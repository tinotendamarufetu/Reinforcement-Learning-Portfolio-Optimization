# Reinforcement-Learning-Portfolio-Optimization Trading Bot ğŸ“ˆğŸ¤–

This project implements a Deep Reinforcement Learning (DRL) agent using **PPO-LSTM** to optimize a portfolio of **ETFs**.  
It uses historical stock data to learn dynamic trading strategies, aiming to maximize returns while minimizing risk.

---

## ğŸš€ Project Overview

- **Framework:** PPO-LSTM (Proximal Policy Optimization with Recurrent Neural Network)
- **Market Data:** 50+ ETFs historical price data (Yahoo Finance)
- **Environment:** Custom OpenAI Gym Trading Environment
- **Evaluation Metrics:**
  - Portfolio Final Value
  - Profit / Returns (%)
  - Sharpe Ratio
  - Maximum Drawdown
  - Total Number of Trades

---

## ğŸ“Š Visualizations

- Portfolio Value Over Time
- Smoothed Rewards Over Time
- Daily Returns
- Trade Penalty Costs
- Portfolio vs. Benchmark Comparison
- Top 5 Performing Stocks (by cumulative profit)
- Drawdown Plot (% from peak)
- Rolling Sharpe Ratio (volatility-adjusted returns)

![image](https://github.com/user-attachments/assets/dbbd120b-12c6-4e58-8698-2fa330addcbf)


---

## ğŸ› ï¸ Project Structure

RL-Trading-Bot/
â”œâ”€â”€ data/
    â”œâ”€â”€ stock_data.csv
â”œâ”€â”€ models/
    â”œâ”€â”€ ppo_model.zip
â”œâ”€â”€ trading_logs/
    â”œâ”€â”€ trading_history.csv
â”œâ”€â”€ environment.py
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md


